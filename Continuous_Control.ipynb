{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:unityagents:\n'Academy' started successfully!\nUnity Academy name: Academy\n        Number of Brains: 1\n        Number of External Brains : 1\n        Lesson number : 0\n        Reset Parameters :\n\t\tgoal_size -> 5.0\n\t\tgoal_speed -> 1.0\nUnity brain name: ReacherBrain\n        Number of Visual Observations (per agent): 0\n        Vector Observation space type: continuous\n        Vector Observation space size (per agent): 33\n        Number of stacked Vector Observation: 1\n        Vector Action space type: continuous\n        Vector Action space size (per agent): 4\n        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='F:/Academic/Udacity RL/deep-reinforcement-learning/p2_continuous-control/Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "#print(brain_name)\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of agents: 1\nSize of each action: 4\nThere are 1 agents. Each observes a state with length: 33\nThe state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74941311 -0.85717058]]\n",
      "[[0.26239269 0.45102055 1.         0.50027387]]\n",
      "[[ 0.40042656 -1.          0.16483495  0.74173512]]\n",
      "[[-0.25872169 -0.03742558 -0.09234011 -0.51109298]]\n",
      "[[ 0.07731574 -0.11320046 -0.88159114 -0.51310018]]\n",
      "[[-1.          0.11773124  0.08289205  1.        ]]\n",
      "[[-0.05884788 -0.87791905  0.97648718  0.49109117]]\n",
      "[[-0.85273496 -0.10615549  0.2720506  -0.19438773]]\n",
      "[[-0.6004207   0.77719361 -0.69949546 -0.57077005]]\n",
      "[[ 0.83560358  0.11158066  0.90067729 -0.06863865]]\n",
      "[[-1.         0.0013272  1.         1.       ]]\n",
      "[[ 0.15130394 -0.76771804  1.         -1.        ]]\n",
      "[[0.12155257 1.         1.         0.06047843]]\n",
      "[[-1.         -0.51524198  0.63733581 -0.32640442]]\n",
      "[[-0.78915724 -0.22584071 -0.17881673 -0.93994606]]\n",
      "[[ 0.07708999  1.          1.         -0.40471971]]\n",
      "[[ 0.55445318 -0.79798941 -0.70341832 -1.        ]]\n",
      "[[-1.         -0.10000772 -0.62222164  1.        ]]\n",
      "[[ 1.         -0.14352187 -0.31555692 -1.        ]]\n",
      "[[ 1.          0.98691185 -0.06045749  0.54721742]]\n",
      "[[-0.89075784 -0.08403278  0.8911099   1.        ]]\n",
      "[[-0.29908326 -0.6593079  -1.          0.014946  ]]\n",
      "[[-0.21804768 -0.0987434  -0.96657673  0.08900395]]\n",
      "[[-0.8653362  -0.79544865 -0.15295225 -0.08473645]]\n",
      "[[ 0.90182118  0.21185987 -0.32271516 -0.36543509]]\n",
      "[[ 1.         -0.68302381  1.          1.        ]]\n",
      "[[ 0.882563   -0.19464541  0.14450956  0.6309627 ]]\n",
      "[[-0.99198021 -0.95551548  1.          1.        ]]\n",
      "[[ 1.         -1.          0.08521241  0.37016121]]\n",
      "[[-0.02318049  0.08263713 -0.50265955 -0.56912327]]\n",
      "[[ 0.23382007 -0.2866866   0.81731444 -1.        ]]\n",
      "[[-0.10739061 -0.28490197 -0.58317933  0.65981405]]\n",
      "[[ 0.34272059 -1.          1.         -1.        ]]\n",
      "[[-1.         -1.         -0.16351786 -0.69982749]]\n",
      "[[ 0.44800859  0.76044929 -0.04817522 -1.        ]]\n",
      "[[ 1.         -1.          0.29389011  0.73321199]]\n",
      "[[ 0.78962075  0.46559133 -0.19769272  0.85992415]]\n",
      "[[-1.          0.09806359  1.         -1.        ]]\n",
      "[[-0.11338969 -0.49589737 -0.4168852   0.3078717 ]]\n",
      "[[ 0.36719362  1.          0.9687736  -1.        ]]\n",
      "[[ 0.10164718 -1.         -0.91190944  1.        ]]\n",
      "[[-1.          1.          0.66089185 -0.08855505]]\n",
      "[[-1.         -0.21094065 -1.          0.47690197]]\n",
      "[[ 1.         -0.29378968  1.         -0.84022749]]\n",
      "[[-0.21440443 -0.26881402 -1.          0.34348112]]\n",
      "[[-0.26039256 -1.          0.9969743  -0.72977344]]\n",
      "[[-1.          0.32499793  0.18467417 -0.12014211]]\n",
      "[[ 0.33325502  1.         -0.405178    0.11258893]]\n",
      "[[-0.9355274  -0.38264927 -1.         -0.7736387 ]]\n",
      "[[ 0.64345676 -0.44114396 -0.49597321  1.        ]]\n",
      "[[-1.          0.48370049 -0.266048    0.11314343]]\n",
      "[[ 0.46766054  0.78867316 -0.69263323 -1.        ]]\n",
      "[[-0.3872536   0.80498971  0.26547207  1.        ]]\n",
      "[[ 1.          0.15143863  1.         -1.        ]]\n",
      "[[ 0.3986358   1.          0.32227851 -0.94826584]]\n",
      "[[-0.25831803  0.53588186  0.98029113  0.02575399]]\n",
      "[[ 0.27602232  0.81192314 -0.17103804  1.        ]]\n",
      "[[ 0.6125641  -1.          0.75244951  0.59042834]]\n",
      "[[-1.00000000e+00  1.00000000e+00 -5.14377123e-01  2.18251813e-04]]\n",
      "[[ 0.35141107 -0.66397155 -0.71936249 -0.59454012]]\n",
      "[[-1.          1.         -0.42533586 -1.        ]]\n",
      "[[0.02332202 0.58673776 0.22751081 1.        ]]\n",
      "[[ 0.7006491  -1.         -0.38568897  0.08181783]]\n",
      "[[ 0.72870909  0.55673616 -0.46291586  0.71056155]]\n",
      "[[-0.05639134 -1.          0.50363491 -1.        ]]\n",
      "[[-0.9464785  -0.06842162 -0.38998513  1.        ]]\n",
      "[[ 1.          1.         -1.         -0.35496406]]\n",
      "[[-0.11080613 -0.18684544  0.14203121 -1.        ]]\n",
      "[[0.63024732 0.86081766 0.22235816 0.4165    ]]\n",
      "[[ 1.         -1.         -0.02294823 -0.44879386]]\n",
      "[[ 0.98853509 -0.41686176 -0.12135626 -1.        ]]\n",
      "[[-0.14014876 -0.64305566 -0.08816389 -1.        ]]\n",
      "[[ 1.         -0.48433559 -0.18266561 -1.        ]]\n",
      "[[ 0.57839137  1.          0.35321777 -1.        ]]\n",
      "[[-0.93661352  0.65307973  0.87988514  1.        ]]\n",
      "[[ 0.38729617 -0.6359201  -0.46783802  1.        ]]\n",
      "[[ 0.93800869  0.59569115 -1.          1.        ]]\n",
      "[[ 0.05124305 -0.41262485 -0.77684846 -0.24264869]]\n",
      "[[-0.50776681 -1.          0.0729406   1.        ]]\n",
      "[[ 0.85381515  0.1059872   0.84064569 -1.        ]]\n",
      "[[-1.         -0.34345273  0.15439862 -0.4594206 ]]\n",
      "[[ 1.         -0.64945728 -0.88498618  0.70284899]]\n",
      "[[-0.39691142  0.34711186 -1.          0.92433294]]\n",
      "[[-0.63774319  1.          1.         -0.94761644]]\n",
      "[[-0.782141   -1.         -0.39319353  0.33205587]]\n",
      "[[-0.79049965 -0.60262064  0.82039479 -1.        ]]\n",
      "[[ 1.         -0.19410916  0.17951592 -0.65414505]]\n",
      "[[ 1.  1. -1. -1.]]\n",
      "[[1.         1.         0.43687363 0.24470457]]\n",
      "[[ 0.55012243  1.          1.         -0.57117223]]\n",
      "[[ 0.75254258  0.05134085  1.         -0.04799429]]\n",
      "[[ 0.88144885 -0.59175604 -0.66346822  1.        ]]\n",
      "[[-0.21174823 -0.71693704  0.35727078  1.        ]]\n",
      "[[-0.56017396  0.6422963   0.35611592  0.62217249]]\n",
      "[[ 1. -1.  1. -1.]]\n",
      "[[-0.53867662  0.53045778  0.99637473 -1.        ]]\n",
      "[[ 0.03060683 -0.25682143  1.          0.85821583]]\n",
      "[[-0.31245568  0.70888756 -0.03017673 -0.66568098]]\n",
      "[[ 0.1086427   1.          0.76612689 -0.72841393]]\n",
      "[[ 0.43744066 -1.         -0.79322708 -0.38107317]]\n",
      "[[ 0.17328848 -1.         -1.          0.38699476]]\n",
      "[[ 1.         -1.         -1.          0.02705097]]\n",
      "[[ 0.8313193  -1.         -0.45623964 -0.02686177]]\n",
      "[[-0.58411407 -1.          1.         -0.18590459]]\n",
      "[[-0.59460166  1.          1.          0.12530912]]\n",
      "[[-0.99618652 -1.         -0.88830007 -0.64322425]]\n",
      "[[-0.37970379  1.          1.         -0.2556801 ]]\n",
      "[[-1.         -0.02723631  0.08551808 -0.05559774]]\n",
      "[[-1.          0.69730255  0.0472281  -0.12351754]]\n",
      "[[ 1.          0.71334745 -0.32905411 -0.142723  ]]\n",
      "[[ 0.50012901 -1.          1.          0.99510841]]\n",
      "[[ 0.43233379  0.0907818  -0.18681161  0.44984573]]\n",
      "[[ 1.         -1.         -1.          0.75286392]]\n",
      "[[ 0.2492226   0.43171262 -0.47520687 -1.        ]]\n",
      "[[-0.59215428 -1.          0.85060651 -1.        ]]\n",
      "[[-1.         -0.40367136 -0.0905872   0.03725868]]\n",
      "[[-1.          1.          0.0133029  -0.80080326]]\n",
      "[[0.12707245 1.         0.19297294 0.6400683 ]]\n",
      "[[ 0.88660723  1.         -0.5791931  -1.        ]]\n",
      "[[ 1.          0.43404204 -0.19586928 -0.31959132]]\n",
      "[[-0.82750299 -0.30342237  0.18218846  1.        ]]\n",
      "[[-1.         -0.94631273  0.4051983  -1.        ]]\n",
      "[[ 0.34193156 -1.          1.         -1.        ]]\n",
      "[[ 0.82117335  1.          0.33759886 -1.        ]]\n",
      "[[ 1.          0.74226203  0.0579271  -0.11656458]]\n",
      "[[-1.         -1.          0.53381787  0.27861864]]\n",
      "[[-0.13462973  0.31313598  0.6150646   0.60927758]]\n",
      "[[ 1.          0.71273174 -1.         -1.        ]]\n",
      "[[-0.02886896 -0.43225764  1.         -0.31894192]]\n",
      "[[ 0.47537661 -0.10333703  0.78641853  0.2088297 ]]\n",
      "[[ 1.         -1.         -0.53695878  0.06792892]]\n",
      "[[ 0.407759    0.91328314 -0.03290807 -0.21439975]]\n",
      "[[-0.34280857 -0.9118042  -0.93867714 -0.68175405]]\n",
      "[[ 1.         -0.03958583 -1.         -0.14564703]]\n",
      "[[-0.70316714 -0.0745931   0.42438259  1.        ]]\n",
      "[[-0.64720295  0.001531   -0.54453793 -1.        ]]\n",
      "[[-1.         -0.76701593  1.          1.        ]]\n",
      "[[ 1.         -0.94210331 -1.         -0.82136163]]\n",
      "[[ 0.11364529  0.67105728  0.88345171 -1.        ]]\n",
      "[[0.40362955 1.         0.40204769 0.59286792]]\n",
      "[[-0.62499634  0.26496936  1.         -0.42925657]]\n",
      "[[ 0.34136254  0.69820486 -0.34384324 -0.04984731]]\n",
      "[[-0.58330337  0.07278503 -0.85304733  1.        ]]\n",
      "[[-1.        -0.8302573  1.        -0.609649 ]]\n",
      "[[ 1.         -0.96645165  0.985191   -0.67729047]]\n",
      "[[ 0.95834576 -0.67543649 -0.70310816 -0.071246  ]]\n",
      "[[-0.45287915  0.56458609 -0.85708987  0.33128694]]\n",
      "[[-0.0601467  -0.12974304 -0.08234273  1.        ]]\n",
      "[[ 0.84236551 -0.13103613 -0.72237795  1.        ]]\n",
      "[[-0.52558358 -1.         -0.31047074  1.        ]]\n",
      "[[-0.89258941  1.          1.          1.        ]]\n",
      "[[ 0.14284807 -0.63787762  0.76950076  0.65820713]]\n",
      "[[1.         0.16374446 1.         0.48332194]]\n",
      "[[ 0.23109727 -0.27187486 -1.          1.        ]]\n",
      "[[-0.08450459 -1.         -0.30850602  1.        ]]\n",
      "[[ 0.49342045 -0.60010842  1.          1.        ]]\n",
      "[[-0.3696674   0.19783342  0.6354045   0.38346786]]\n",
      "[[ 1.         -0.00716995  1.         -1.        ]]\n",
      "[[ 0.30230698 -0.55866103  0.33216679 -0.37224027]]\n",
      "[[-1.          1.         -0.18528459 -0.77715507]]\n",
      "[[ 1.         -1.          0.31850564  0.91427056]]\n",
      "[[ 0.15539984  0.89474328  0.291249   -0.54332016]]\n",
      "[[-0.41723406 -1.          0.15626595  0.35762481]]\n",
      "[[ 0.19361466 -1.          1.          0.59735849]]\n",
      "[[ 1.         -0.35242847 -1.          1.        ]]\n",
      "[[ 0.55558757  0.34903543  0.71525998 -0.29678115]]\n",
      "[[ 0.15251703  0.92206536 -0.37256456  0.1370022 ]]\n",
      "[[-0.07714842  0.96169527 -0.387216   -0.33587752]]\n",
      "[[ 0.66273091 -0.49289457  0.50766608  1.        ]]\n",
      "[[ 0.06014422  0.79508798 -0.31700598  0.13344264]]\n",
      "[[-1.         -0.15927274 -0.21690498 -0.19045941]]\n",
      "[[ 0.0077367  -0.18724758 -0.09508272 -1.        ]]\n",
      "[[-0.04123961  0.28949712 -0.1844809  -0.1989579 ]]\n",
      "[[-1.         -0.68841617  0.03188606 -1.        ]]\n",
      "[[ 0.33402729  1.          0.06993552 -0.69507745]]\n",
      "[[ 0.95469705 -0.31292738 -0.349618   -0.3586909 ]]\n",
      "[[ 0.03435278  0.79258851  0.42462501 -0.06171179]]\n",
      "[[-0.8549234  -1.         -0.28387348 -0.32751933]]\n",
      "[[ 0.6950136  -0.26946211  1.          0.82740203]]\n",
      "[[ 0.73735176  1.          0.3969148  -0.19866256]]\n",
      "[[-1.         -0.52352127  1.         -1.        ]]\n",
      "[[ 1.          0.48304794  1.         -0.8002343 ]]\n",
      "[[ 1.         -0.29500975 -1.          1.        ]]\n",
      "[[ 0.75339655 -1.          0.40983382  0.09203321]]\n",
      "[[1.         0.22435503 1.         0.03723804]]\n",
      "[[-0.62853415  0.43197744  1.          0.28038129]]\n",
      "[[-1.         -1.         -0.67683224 -0.49058328]]\n",
      "[[-1.          0.4691444  -0.35417534  1.        ]]\n",
      "[[ 1.          0.41845773 -0.41319678 -1.        ]]\n",
      "[[ 0.13525352  1.         -0.2335557  -0.79645721]]\n",
      "[[ 0.67604375 -0.64361983  1.         -0.32225357]]\n",
      "[[-1.          0.45559287 -0.33504097 -0.64405368]]\n",
      "[[-0.09310816 -0.38778522  1.          0.32743956]]\n",
      "[[-0.83349939  0.06640923  0.841959    0.47762542]]\n",
      "[[-0.24368912  0.8468032   0.81649676 -0.73411257]]\n",
      "[[-0.25108935 -1.          1.         -0.56269594]]\n",
      "[[-1.         -0.05958748 -1.          1.        ]]\n",
      "[[-0.42174705  1.          1.         -0.39115706]]\n",
      "[[-1.          0.93946378 -1.          0.80730192]]\n",
      "[[ 0.64783759 -0.96480295 -0.2523355   0.12910263]]\n",
      "[[-1.          1.         -1.          0.73020243]]\n",
      "[[-0.2124685  -0.06484933 -0.36639957 -0.37650581]]\n",
      "[[ 0.18803461  1.         -1.         -1.        ]]\n",
      "[[-0.06563333  1.          1.          0.37594588]]\n",
      "[[ 0.43974756  1.         -1.         -0.36954937]]\n",
      "[[-0.43586125  0.25452138  1.          1.        ]]\n",
      "[[ 0.86842371  1.          0.6110124  -0.7895337 ]]\n",
      "[[-0.41497184 -0.09430792  0.55333596 -1.        ]]\n",
      "[[ 1.         -1.          0.14162928 -0.46907369]]\n",
      "[[ 1.         -0.44354217 -0.43660736 -1.        ]]\n",
      "[[-0.53425888 -0.44792533 -0.30758894 -1.        ]]\n",
      "[[-0.22999078 -0.91211241 -1.         -0.06865221]]\n",
      "[[-0.0863229   1.          0.66397138  0.05636251]]\n",
      "[[ 0.63939201 -0.81743588 -1.         -0.61196213]]\n",
      "[[-1.          0.63318321  1.          1.        ]]\n",
      "[[ 1.        -1.        -1.         0.4306055]]\n",
      "[[-0.90045783  0.80934786  0.6584873   0.13932045]]\n",
      "[[-0.38317564  0.08013914  1.          0.48553045]]\n",
      "[[ 0.0563712   0.13339347  1.         -0.33201358]]\n",
      "[[-0.39988728 -1.         -0.26476602  0.21849761]]\n",
      "[[ 0.65977739  0.40455301 -1.         -0.13679432]]\n",
      "[[ 0.64019822 -0.31506844 -1.         -1.        ]]\n",
      "[[-1.          1.          1.          0.27758855]]\n",
      "[[-0.16356377  1.          0.06542383 -0.00777256]]\n",
      "[[ 1.          1.         -0.50342668 -0.53987561]]\n",
      "[[-1.         -0.12565025 -0.91975047  1.        ]]\n",
      "[[-0.1959266  1.        -1.         1.       ]]\n",
      "[[ 1.         -1.         -0.88883433  0.40743451]]\n",
      "[[-0.54844422 -0.20684003 -0.31369298 -0.0450339 ]]\n",
      "[[ 0.39391953  0.83168979 -0.05817362 -0.79372842]]\n",
      "[[ 0.55625277  1.         -0.21038623 -0.6219362 ]]\n",
      "[[-0.76329499 -0.52459361 -0.53443213 -1.        ]]\n",
      "[[ 0.04540754 -0.7482929   0.61734855  0.48319194]]\n",
      "[[-1.         -1.          0.40956638  0.35515403]]\n",
      "[[-0.35835404 -1.          0.03659785  0.15990461]]\n",
      "[[-0.02685061  1.          1.         -0.20407876]]\n",
      "[[ 0.03050908 -0.95049341  1.         -1.        ]]\n",
      "[[-0.06080025 -0.39863864  0.12634013  1.        ]]\n",
      "[[ 0.42557497 -0.46125656 -0.93104793 -0.80250728]]\n",
      "[[ 0.82157881 -0.1353668  -0.84880629 -0.93805227]]\n",
      "[[ 1.         -0.58825343  0.30759297  1.        ]]\n",
      "[[-1.         -0.54913396  0.36564834 -0.50052907]]\n",
      "[[-0.11486113  1.         -1.          0.17802883]]\n",
      "[[-1.          0.60006039  0.53039128 -0.84619489]]\n",
      "[[ 1. -1.  1.  1.]]\n",
      "[[-0.42148875 -1.         -1.         -1.        ]]\n",
      "[[0.16464756 1.         0.83302875 0.84941213]]\n",
      "[[ 0.46917751  0.43175113 -0.60700925 -0.34732899]]\n",
      "[[-0.32585756  1.          1.          0.7479745 ]]\n",
      "[[ 0.62688646 -1.         -0.74734561 -0.60039594]]\n",
      "[[-0.91786441  1.          0.27215006 -0.5431499 ]]\n",
      "[[-0.87528475 -0.4438834  -1.          0.40954889]]\n",
      "[[-0.47314426  0.12225344 -0.16664045  1.        ]]\n",
      "[[-0.73643218 -0.50299891 -0.68319887  1.        ]]\n",
      "[[-1.         -0.88375925 -1.          1.        ]]\n",
      "[[ 1.          0.88504696 -0.44441358  0.20754116]]\n",
      "[[-0.78473732 -0.08644552  0.91458933  1.        ]]\n",
      "[[-0.68036434 -0.5096272  -0.82134531  0.04661705]]\n",
      "[[-0.8453636   0.35389674 -0.67254293 -1.        ]]\n",
      "[[-1.          0.07130348 -1.         -1.        ]]\n",
      "[[ 0.46965027 -1.          0.31550977 -0.75215813]]\n",
      "[[-0.23022012  1.          0.30595305  0.69140268]]\n",
      "[[0.44886813 0.57234399 1.         0.82785314]]\n",
      "[[ 0.1195993   0.5382371   1.         -0.91049516]]\n",
      "[[ 1.          0.80085134  0.79468331 -1.        ]]\n",
      "[[-1.          0.90418406  1.         -0.52924167]]\n",
      "[[-1.         -1.         -1.          0.45134282]]\n",
      "[[ 1.         -1.          0.20174452  0.73756625]]\n",
      "[[ 1.         -0.32023967 -0.04859445  1.        ]]\n",
      "[[ 1. -1.  1. -1.]]\n",
      "[[1.         0.54353796 1.         0.06837833]]\n",
      "[[ 0.96723154 -0.45614692 -0.4243796  -1.        ]]\n",
      "[[-0.34841065 -0.04162074 -0.73032206 -0.88670574]]\n",
      "[[-0.62658044  0.38609817  0.26121253  0.27391912]]\n",
      "[[-0.8666555  -1.          1.         -0.72533371]]\n",
      "[[ 0.92109421 -1.          0.52633977  0.14129265]]\n",
      "[[-0.17016332  0.63540079 -0.96638307 -0.09152201]]\n",
      "[[-0.86083824  0.35098422  1.         -0.00440593]]\n",
      "[[ 1.         -0.9687263  -1.         -0.22987038]]\n",
      "[[ 0.24777681 -1.         -0.72780105  1.        ]]\n",
      "[[1.         0.60297264 1.         0.59131334]]\n",
      "[[-0.18298881 -1.          1.          0.24114478]]\n",
      "[[ 0.02250087 -0.62735857 -0.01487537 -1.        ]]\n",
      "[[-0.1616338  -1.          1.          0.96791161]]\n",
      "[[-1.          1.         -0.02781638  0.48613736]]\n",
      "[[ 1.         -0.19015007 -0.60031472  0.42203063]]\n",
      "[[-0.52671736 -0.42588498 -0.15783053  0.41009162]]\n",
      "[[-0.66590633  0.27315005  0.22881303  0.01439775]]\n",
      "[[-0.12174441 -1.          0.35597539 -1.        ]]\n",
      "[[ 1.         -0.00150586  0.3382736   0.191669  ]]\n",
      "[[-1.         -0.30687652 -1.          1.        ]]\n",
      "[[-1.          1.          0.03209722 -1.        ]]\n",
      "[[-0.33428677 -0.90969049 -1.          0.81487725]]\n",
      "[[-0.79795305  1.         -1.         -0.52722603]]\n",
      "[[ 0.05148851 -0.46081087  0.47138462 -1.        ]]\n",
      "[[-1.          0.0019067   1.          0.31285344]]\n",
      "[[ 0.58730183 -0.54832898  0.89439713 -1.        ]]\n",
      "[[-0.61326178  0.45783268  1.         -0.01007471]]\n",
      "[[ 1.          0.47577591  0.91919994 -0.45599858]]\n",
      "[[-0.33210911 -1.          0.64528511 -0.90094078]]\n",
      "[[ 0.98789493  1.         -0.22763158  0.85796217]]\n",
      "[[ 0.36176143 -0.33540078 -1.         -0.94157782]]\n",
      "[[-1.         -1.         -1.         -0.22099897]]\n",
      "[[0.22863899 0.98695481 1.         1.        ]]\n",
      "[[-0.82241171  0.18790723  1.         -1.        ]]\n",
      "[[ 0.65240516 -0.28615952  1.         -1.        ]]\n",
      "[[ 0.24001076 -0.80342108 -0.52119427 -0.01208505]]\n",
      "[[-0.46250431 -0.04365251  0.36852938  0.08684452]]\n",
      "[[ 0.98589566 -1.         -1.          1.        ]]\n",
      "[[-1.         -0.39556684 -0.66203574 -0.16072431]]\n",
      "[[-0.44722976  0.21966949  0.41600524  0.90068074]]\n",
      "[[ 0.62723632 -0.28962179 -1.          1.        ]]\n",
      "[[0.37466446 0.87243174 0.73869564 0.50431478]]\n",
      "[[-0.77978432 -1.         -1.          1.        ]]\n",
      "[[0.57298254 0.60125068 0.85527129 0.0158205 ]]\n",
      "[[ 1.          1.         -0.42108856  0.86696853]]\n",
      "[[ 0.09733835 -1.          0.95472118  0.15092836]]\n",
      "[[1. 1. 1. 1.]]\n",
      "[[-1.          1.          1.         -0.15950276]]\n",
      "[[ 0.55162148 -0.12573986  0.82147023 -1.        ]]\n",
      "[[ 0.15129662  1.         -0.06656186  0.08768434]]\n",
      "[[-1.         -0.51005093 -0.09010035  1.        ]]\n",
      "[[ 0.56693979  0.80678873 -0.49593295  0.15494649]]\n",
      "[[ 1.          0.90553932  1.         -0.36058747]]\n",
      "[[ 0.46266621  0.50130001 -0.7400612   1.        ]]\n",
      "[[1.         0.48085051 0.47168744 1.        ]]\n",
      "[[-0.5264308   0.74302397  0.14923784 -1.        ]]\n",
      "[[-0.34230509  1.          0.3263702   1.        ]]\n",
      "[[ 0.20056125 -0.96879997 -1.          0.0421795 ]]\n",
      "[[-1.          0.74238981 -0.43122229  0.13957384]]\n",
      "[[-0.30504295 -0.15562518  0.68531175  1.        ]]\n",
      "[[1.         0.65659361 0.06816477 1.        ]]\n",
      "[[-0.57838747  1.         -0.36408451  0.50484248]]\n",
      "[[ 0.15017386  0.98375819 -0.17094304 -0.33264206]]\n",
      "[[-0.15681798  1.         -0.09871026  1.        ]]\n",
      "[[ 0.08076494 -0.91431476 -1.         -0.06151345]]\n",
      "[[-0.41861401 -1.          1.         -0.72657672]]\n",
      "[[ 0.37565962 -0.71233354  0.21788943  0.20032128]]\n",
      "[[ 0.37304517  1.         -1.          0.20666297]]\n",
      "[[-0.81029272 -0.79813675  0.06836159 -0.86854263]]\n",
      "[[ 0.97051524  0.77276896 -0.4859871  -0.538138  ]]\n",
      "[[-0.01902999  0.56942608 -0.95600568 -0.69719427]]\n",
      "[[-0.39675105  0.26291291  0.62331879 -0.64164034]]\n",
      "[[-0.06176162  0.73244577 -1.         -0.59832648]]\n",
      "[[ 0.64094869  1.         -0.5093336  -0.00865743]]\n",
      "[[ 1.         -0.51591831  0.09023744  0.13008778]]\n",
      "[[ 1.          0.76643214 -0.26018184 -1.        ]]\n",
      "[[ 1.         -1.          0.37747671 -1.        ]]\n",
      "[[-0.36166077 -0.0592321   0.35957301  1.        ]]\n",
      "[[-0.46423764  0.83516594 -1.         -0.00292221]]\n",
      "[[-1.          1.          0.89369544 -0.7456361 ]]\n",
      "[[-0.04727233  1.         -1.          0.91120585]]\n",
      "[[-0.37788065 -0.10614377 -1.         -0.39503587]]\n",
      "[[-0.77144443  0.01660013 -0.80574553 -1.        ]]\n",
      "[[ 0.9911266  -0.96367352  0.02486146  0.44104296]]\n",
      "[[ 0.3419567  -0.21819596  0.26489728  0.41696439]]\n",
      "[[ 0.28262223  0.75923351 -0.71460153 -0.85964017]]\n",
      "[[ 0.40470267  0.06937763  0.53351906 -0.30527129]]\n",
      "[[ 1.          0.32586167 -1.         -0.29620072]]\n",
      "[[ 0.92360274  0.90586763  0.28430399 -1.        ]]\n",
      "[[-0.02351001 -0.07238077  1.         -1.        ]]\n",
      "[[ 0.32676697 -0.02963778  0.09340099 -0.39282752]]\n",
      "[[-1.         -1.          0.06515086 -0.00740852]]\n",
      "[[ 0.44213501  0.44367515  1.         -0.53145053]]\n",
      "[[ 0.36610772  1.         -1.          0.14378808]]\n",
      "[[ 0.75781514 -0.31885829  1.         -1.        ]]\n",
      "[[-0.01599338  0.0158089   1.         -1.        ]]\n",
      "[[ 0.98150545  0.0608767   0.01094508 -0.43860164]]\n",
      "[[-1.         -1.          0.33250898 -1.        ]]\n",
      "[[ 0.05081908 -1.         -0.74033145  1.        ]]\n",
      "[[-0.68366234  0.45471996 -0.1379776  -0.38049222]]\n",
      "[[-0.19626422 -0.62749212  0.35474982 -0.6109188 ]]\n",
      "[[0.10358   0.2724409 1.        1.       ]]\n",
      "[[0.20577327 1.         0.35472361 1.        ]]\n",
      "[[-0.51183009  0.65646757  0.32950245 -0.89481055]]\n",
      "[[-0.59368002 -1.         -0.7901806   0.78611304]]\n",
      "[[ 1.         -1.          0.34301411 -0.82225263]]\n",
      "[[-0.27583958 -1.          0.38492273 -0.63877223]]\n",
      "[[ 0.11800485 -1.         -0.8707691   0.92627549]]\n",
      "[[-1.         -0.28594857 -0.61994698  0.24213211]]\n",
      "[[ 0.84936367 -0.25348193 -0.51959962 -1.        ]]\n",
      "[[ 1.          0.35302759  1.         -0.57588415]]\n",
      "[[-0.09106339 -1.          0.343204    0.51609431]]\n",
      "[[ 0.3195203   0.77379922  0.8013033  -1.        ]]\n",
      "[[-1.         -1.         -0.78905225  0.94280712]]\n",
      "[[-0.19589613 -0.58378698  1.         -1.        ]]\n",
      "[[0.84758028 1.         0.18254652 0.78655323]]\n",
      "[[-0.03549556 -1.         -1.         -0.76675391]]\n",
      "[[ 0.23159011  1.         -0.10363027  1.        ]]\n",
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    print(actions)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=600, fc2_units=600):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.tanh(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=600, fc2_units=600):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "#from model import Actor, Critic\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99               # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 1e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval() #set to test mode so we can evaluate expected action\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()# set the model back to train mode so we can train the paras\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state)) #bellman equation\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets) #Advantage function??\n",
    "        # Minimize the loss\n",
    "        # self.critic_optimizer.zero_grad()\n",
    "        # critic_loss.backward()\n",
    "        # self.critic_optimizer.step()\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(self.size)#np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode 15\tAverage Score: 0.05"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9a7c33f79228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# fig = plt.figure()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-9a7c33f79228>\u001b[0m in \u001b[0;36mddpg\u001b[1;34m(n_episodes, max_t, print_every)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m#action = agent.act(state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#np.random.randn(num_agents, action_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;31m#print(actions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#actions = np.clip(actions, -1, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-b60edc08e335>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, add_noise)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"\"\"Returns actions for given state as per current policy.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set to test mode so we can evaluate expected action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2)\n",
    "def ddpg(n_episodes=500, max_t=1000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #state = env.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations[0]\n",
    "        #print(states)\n",
    "        agent.reset()\n",
    "        #score = 0\n",
    "        scores = np.zeros(num_agents) \n",
    "        #print(scores)\n",
    "        #for t in range(max_t):\n",
    "        count = 0\n",
    "        \n",
    "        while True:\n",
    "            #action = agent.act(state)\n",
    "            count += 1\n",
    "            actions = agent.act(states, add_noise=True)#np.random.randn(num_agents, action_size)\n",
    "            #print(actions)\n",
    "            #actions = np.clip(actions, -1, 1) \n",
    "            env_info = env.step(actions)[brain_name] \n",
    "            next_states = env_info.vector_observations[0]\n",
    "            #next_state, reward, done, _ = env.step(action)\n",
    "            rewards = env_info.rewards                         \n",
    "            dones = env_info.local_done\n",
    "            #if np.any(rewards):\n",
    "                #print(rewards, scores)  \n",
    "            #agent.step(state, action, reward, next_state, done)\n",
    "            #print(rewards, dones, scores)\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            scores += env_info.rewards\n",
    "            #state = next_state\n",
    "            states = next_states\n",
    "            #score += reward\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        scores_deque.append(scores)\n",
    "        #print(count)\n",
    "        #print(scores)\n",
    "        #scores.append(scores)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "\n",
    "        \n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "# plt.ylabel('Score')\n",
    "# plt.xlabel('Episode #')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2)\n",
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0.16952708 -0.99999994  0.9927173  -1.        ]\n",
      "[-0.99299574 -1.          0.9999104  -1.        ]\n",
      "[-0.9999998 -1.         1.        -1.       ]\n",
      "[-1. -1.  1. -1.]\n",
      "[-1. -1.  1. -1.]\n",
      "[-1.         -1.          0.99999994 -1.        ]\n",
      "[-1.         -0.9999776   0.99944425 -0.99995357]\n",
      "[-1.         -0.86201155  0.9916225  -0.98697203]\n",
      "[-0.9999999  0.9237167  0.9665055 -0.8003906]\n",
      "[-0.99998736  0.99915504  0.9422322   0.8570612 ]\n",
      "[-0.9957919   0.9999513   0.91181904  0.9992427 ]\n",
      "[-0.249976   0.9999778  0.984446   0.9999911]\n",
      "[0.9590657  0.99999166 0.9962493  0.9999997 ]\n",
      "[0.9999361  0.9999993  0.99957687 1.        ]\n",
      "[1.         0.99999976 0.99999744 1.        ]\n",
      "[1.        0.9999992 1.        1.       ]\n",
      "[1.         0.6352967  1.         0.99999994]\n",
      "[ 1.         -1.          1.          0.99267095]\n",
      "[ 1.         -1.          1.         -0.99787104]\n",
      "[ 0.9998085 -1.         1.        -0.9931486]\n",
      "[ 0.9617196 -1.         1.        -0.9539636]\n",
      "[ 0.9168363  -1.          1.         -0.33421662]\n",
      "[ 0.98229206 -1.          1.         -0.46629944]\n",
      "[ 0.9999553  -0.9999992   1.          0.30825856]\n",
      "[ 0.99999994 -0.85019404  0.9999999   0.98619723]\n",
      "[1.         0.99993557 0.99999994 0.99999815]\n",
      "[1.         0.99999875 1.         1.        ]\n",
      "[1. 1. 1. 1.]\n",
      "[1.         1.         1.         0.99999994]\n",
      "[1.         0.99999994 1.         0.9999997 ]\n",
      "[1.         0.9999997  1.         0.99999833]\n",
      "[1.        0.9999995 1.        0.9999889]\n",
      "[1.         0.9999996  1.         0.99996513]\n",
      "[1.        0.9999997 1.        0.9999708]\n",
      "[1.        0.9999431 1.        0.9997449]\n",
      "[ 1.        -0.9999997  1.        -0.9505205]\n",
      "[ 1.         -1.          1.         -0.99999994]\n",
      "[ 1.        -0.9999998  1.        -1.       ]\n",
      "[ 1.         -0.99855244  1.         -1.        ]\n",
      "[ 1.          0.35517666  1.         -1.        ]\n",
      "[ 1.         0.9980085  1.        -1.       ]\n",
      "[ 1.         0.9999855  1.        -1.       ]\n",
      "[ 1.          0.99999976  1.         -1.        ]\n",
      "[ 1.  1.  1. -1.]\n",
      "[ 1.  1.  1. -1.]\n",
      "[ 1.          1.          0.99999714 -1.        ]\n",
      "[ 1.         1.         0.9992777 -1.       ]\n",
      "[ 1.          0.99999994  0.9029852  -1.        ]\n",
      "[ 1.         0.999999  -0.8366057 -1.       ]\n",
      "[ 1.         0.9998457 -0.9992636 -1.       ]\n",
      "[ 0.99999994  0.9982797  -0.9922468  -1.        ]\n",
      "[ 1.          0.9985499  -0.99709135 -1.        ]\n",
      "[ 1.          0.99663407 -0.9997297  -1.        ]\n",
      "[ 1.         0.9792882 -0.999983  -1.       ]\n",
      "[ 1.         -0.9366085  -0.99999654 -1.        ]\n",
      "[ 1.        -0.9999998 -1.        -1.       ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.99629766 -1.         -1.         -1.        ]\n",
      "[-0.9811689 -1.        -1.        -1.       ]\n",
      "[-0.9938789 -1.        -1.        -1.       ]\n",
      "[-0.9952549 -1.        -1.        -1.       ]\n",
      "[-0.9990822 -1.        -1.        -1.       ]\n",
      "[-0.9999459  -1.         -0.84337413 -1.        ]\n",
      "[-0.9999879  -1.          0.99999934 -1.        ]\n",
      "[-0.9742535  -1.         -0.99997926 -1.        ]\n",
      "[-0.4685235  -1.          0.99994034 -1.        ]\n",
      "[ 0.5680683  -1.         -0.31328905 -1.        ]\n",
      "[ 0.4840292  -1.          0.84685993 -1.        ]\n",
      "[ 0.9857385  -0.99919015 -0.999939   -1.        ]\n",
      "[ 0.8598326 -1.         0.9256501 -1.       ]\n",
      "[ 0.9990499 -0.9888941 -0.9951392 -1.       ]\n",
      "[ 0.9835151 -0.9999958  0.9895073 -1.       ]\n",
      "[ 0.9430623  -0.9998501   0.99413615 -1.        ]\n",
      "[-0.7761726  -0.99996084  0.9998504  -1.        ]\n",
      "[-0.99984914 -0.99963474  0.9998939  -1.        ]\n",
      "[-0.9999999  -0.9999912   0.99992436 -1.        ]\n",
      "[-1.         -1.          0.99999285 -1.        ]\n",
      "[-1.        -1.         0.9999975 -1.       ]\n",
      "[-1.        -1.         0.9998619 -1.       ]\n",
      "[-0.99999386 -0.99999994  0.99957013 -0.99998355]\n",
      "[-0.9999999  -1.          1.         -0.99999976]\n",
      "[-1. -1.  1. -1.]\n",
      "[-1. -1.  1. -1.]\n",
      "[-1.         -1.          0.99999255 -1.        ]\n",
      "[-1.        -0.9999992  0.9174117 -1.       ]\n",
      "[-0.99952114 -0.9999964  -0.97319365 -0.99999994]\n",
      "[ 0.95638156 -0.997149   -0.99999994 -1.        ]\n",
      "[ 0.99998575 -0.9766254  -1.         -1.        ]\n",
      "[ 0.99999976 -0.9998453  -1.         -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.9999108 -1.        -1.        -1.       ]\n",
      "[-0.9999998 -1.        -1.        -1.       ]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1.        -1.        -0.9999963 -1.       ]\n",
      "[-0.9999998 -1.         0.2087697 -1.       ]\n",
      "[-1.        -1.        -0.9999986 -1.       ]\n",
      "[-0.99991745 -1.          0.17853479 -1.        ]\n",
      "[-0.99987197 -1.          0.9907636  -1.        ]\n",
      "[-0.99976957 -1.          0.2931234  -1.        ]\n",
      "[-0.99996513 -1.          0.9987217  -1.        ]\n",
      "[-0.99999964 -1.          0.99999774 -1.        ]\n",
      "[-1.         -0.99999815  0.9998911  -1.        ]\n",
      "[-0.9999755 -0.7490441 -0.9902008 -1.       ]\n",
      "[-0.99996126 -0.9999648   0.77809644 -1.        ]\n",
      "[-0.9967436  -1.          0.88987964 -1.        ]\n",
      "[ 0.54771173 -1.          0.8410671  -1.        ]\n",
      "[-0.87099767 -0.9995203  -0.14019106 -1.        ]\n",
      "[ 0.46998608 -0.9731969  -0.96761775 -1.        ]\n",
      "[ 0.39744022 -0.6246402  -0.99614346 -1.        ]\n",
      "[ 0.45541295 -0.74683595 -0.9974142  -1.        ]\n",
      "[ 0.33367303 -0.8070716  -0.99867904 -1.        ]\n",
      "[ 0.44630867 -0.9842946  -0.9990882  -1.        ]\n",
      "[-0.07410534 -0.9942594  -0.9996841  -1.        ]\n",
      "[ 0.4975554  -0.99999994 -0.97980696 -1.        ]\n",
      "[-0.83904517 -0.99999356 -0.9999437  -1.        ]\n",
      "[-0.24505825 -1.         -0.98550415 -1.        ]\n",
      "[-0.40150797 -1.         -0.9973328  -1.        ]\n",
      "[-0.54807353 -1.         -0.9994017  -1.        ]\n",
      "[-0.75455093 -1.         -0.9998653  -1.        ]\n",
      "[-0.91800356 -1.         -0.99998116 -1.        ]\n",
      "[-0.97669464 -1.         -0.9999988  -1.        ]\n",
      "[-0.99485135 -1.         -0.99999994 -1.        ]\n",
      "[-0.9962079 -1.        -1.        -1.       ]\n",
      "[-0.98625994 -0.99999994 -1.         -1.        ]\n",
      "[-0.79226077 -0.99999225 -1.         -1.        ]\n",
      "[ 0.4975709 -0.9998614 -1.        -1.       ]\n",
      "[ 0.07059866 -0.99946606 -1.         -1.        ]\n",
      "[ 0.91721   -0.9990741 -1.        -1.       ]\n",
      "[ 0.93750465 -0.9972258  -1.         -1.        ]\n",
      "[ 0.9623577  -0.99761367 -1.         -1.        ]\n",
      "[ 0.9730188 -0.9995971 -1.        -1.       ]\n",
      "[ 0.9831663  -0.99999034 -1.         -1.        ]\n",
      "[ 0.9858033 -1.        -1.        -1.       ]\n",
      "[ 0.992241 -1.       -1.       -1.      ]\n",
      "[ 0.9997939 -1.        -1.        -1.       ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1.        -0.9999998 -1.        -1.       ]\n",
      "[ 1.        -0.9999022 -1.        -1.       ]\n",
      "[ 0.9999997 -0.9997111 -1.        -1.       ]\n",
      "[ 0.99999976 -0.99999154 -1.         -1.        ]\n",
      "[ 0.99999994 -0.9999997  -1.         -1.        ]\n",
      "[ 1.         -0.99999994 -1.         -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1.         -0.99999994 -1.         -1.        ]\n",
      "[ 1.        -0.9999999 -1.        -1.       ]\n",
      "[ 1.        -0.9999997 -1.        -1.       ]\n",
      "[ 0.9999999 -0.9999997 -1.        -1.       ]\n",
      "[ 0.9999964  -0.99999994 -1.         -1.        ]\n",
      "[ 0.9997545 -1.        -1.        -1.       ]\n",
      "[ 0.9497825 -1.        -1.        -1.       ]\n",
      "[-0.88077784 -1.         -1.         -1.        ]\n",
      "[-0.21976238 -1.         -1.         -1.        ]\n",
      "[-0.15360722 -1.         -1.         -1.        ]\n",
      "[-0.8449644  -1.         -0.99999976 -1.        ]\n",
      "[-0.9984049  -1.         -0.99956965 -1.        ]\n",
      "[-0.9999724 -1.        -0.9691025 -1.       ]\n",
      "[-0.9996665 -1.        -0.9779695 -1.       ]\n",
      "[-0.99694777 -1.         -0.9710432  -1.        ]\n",
      "[-0.9328728 -1.        -0.9677318 -1.       ]\n",
      "[ 0.80673057 -1.         -0.9889935  -1.        ]\n",
      "[ 0.998884  -1.        -0.9962546 -1.       ]\n",
      "[ 0.99998534 -1.         -0.99979633 -1.        ]\n",
      "[ 0.99999726 -1.         -0.9998963  -1.        ]\n",
      "[ 0.9999978 -1.        -0.9995693 -1.       ]\n",
      "[ 0.99998736 -1.         -0.99570745 -1.        ]\n",
      "[ 0.9998311 -1.        -0.972223  -1.       ]\n",
      "[ 0.9990717 -1.        -0.9526436 -1.       ]\n",
      "[ 0.99525404 -1.         -0.9516682  -1.        ]\n",
      "[ 0.9953102  -1.         -0.97939867 -1.        ]\n",
      "[ 0.9995028  -1.         -0.99537843 -1.        ]\n",
      "[ 0.99999946 -1.         -0.9990383  -1.        ]\n",
      "[ 1.        -1.        -0.9998848 -1.       ]\n",
      "[ 1.        -1.        -0.9999632 -1.       ]\n",
      "[ 1.        -1.        -0.9998983 -1.       ]\n",
      "[ 1.        -1.        -0.9991073 -1.       ]\n",
      "[ 1.         -1.         -0.96838784 -1.        ]\n",
      "[ 1.        -1.         0.5420511 -1.       ]\n",
      "[ 0.99999994 -1.          0.47188848 -1.        ]\n",
      "[ 0.9891586 -0.9999999  0.5944058 -1.       ]\n",
      "[-0.9991432  -0.99999976  0.32400566 -1.        ]\n",
      "[-0.99999774 -0.99999684  0.9887422  -1.        ]\n",
      "[-0.9999984  -0.99973595  0.5712718  -0.99999964]\n",
      "[-0.999999   -0.9999829   0.9828212  -0.99999005]\n",
      "[-0.9453874  -0.99999976  0.9989628  -0.9999985 ]\n",
      "[ 0.54084265 -1.          0.9998655  -0.9999994 ]\n",
      "[-0.99860036 -1.          0.9985934  -0.99999774]\n",
      "[ 0.7717418  -1.          0.99972975 -0.99999994]\n",
      "[-0.99785477 -1.          0.9981383  -1.        ]\n",
      "[ 0.60237217 -1.          0.9996137  -1.        ]\n",
      "[-0.984706   -1.          0.99855715 -1.        ]\n",
      "[-0.28632012 -1.          0.9992392  -1.        ]\n",
      "[ 0.21348926 -1.          0.9990796  -1.        ]\n",
      "[-0.34650725 -1.          0.9998519  -1.        ]\n",
      "[-0.55127454 -1.          0.9999999  -1.        ]\n",
      "[ 0.3943573 -1.         1.        -1.       ]\n",
      "[ 0.9998921 -1.         1.        -1.       ]\n",
      "[ 0.6550737 -1.         1.        -1.       ]\n",
      "[-0.87743646 -0.9999938   0.9998005  -1.        ]\n",
      "[-0.99961174 -0.9999946   0.99964905 -1.        ]\n",
      "[-0.99999994 -1.          0.99999976 -1.        ]\n",
      "[-1. -1.  1. -1.]\n",
      "[-1.         -1.          1.         -0.99999857]\n",
      "[-0.1687222  -0.99999624 -0.9841998  -0.99999803]\n",
      "[ 0.9999994 -0.9999989  0.9956223 -0.9999746]\n",
      "[-0.9900558 -0.9999967  0.8038392 -0.9998942]\n",
      "[-0.35816085 -0.99999976  0.97834516 -0.9999875 ]\n",
      "[-0.9653554 -0.9999995  0.9998781 -0.9952067]\n",
      "[-0.940531   -0.99999994  0.9999955  -0.9327508 ]\n",
      "[-0.9864428  -1.          0.99999934 -0.9999821 ]\n",
      "[-0.9984817 -1.         0.9999999 -1.       ]\n",
      "[-0.99948967 -1.          0.99999994 -1.        ]\n",
      "[-0.9996975 -1.         1.        -1.       ]\n",
      "[-0.99652547 -1.          1.         -1.        ]\n",
      "[-0.13264447 -1.          1.         -1.        ]\n",
      "[ 0.9999893  -1.          1.         -0.99999994]\n",
      "[ 0.9999999 -1.         1.        -0.9999814]\n",
      "[ 0.99885136 -1.          1.         -0.9999999 ]\n",
      "[-0.87950236 -1.          1.         -1.        ]\n",
      "[-0.9992158 -1.         1.        -1.       ]\n",
      "[-0.9997764  -1.          1.         -0.99999994]\n",
      "[-0.9994939 -1.         1.        -0.999998 ]\n",
      "[-0.98756576 -1.          1.         -0.9997572 ]\n",
      "[-0.67796385 -0.99999994  1.         -0.9960411 ]\n",
      "[ 0.79401416 -1.          1.         -0.99503696]\n",
      "[ 0.99988145 -0.99999994  1.         -0.9996061 ]\n",
      "[ 0.9582707 -1.         1.        -0.999997 ]\n",
      "[ 0.808472   -1.          1.         -0.99999976]\n",
      "[ 0.82381153 -1.          1.         -1.        ]\n",
      "[ 0.9752603 -1.         1.        -1.       ]\n",
      "[ 0.99882877 -1.          1.         -1.        ]\n",
      "[ 0.99995875 -0.99999994  1.         -1.        ]\n",
      "[ 0.9999994 -0.9999999  1.        -1.       ]\n",
      "[ 1. -1.  1. -1.]\n",
      "[ 1. -1.  1. -1.]\n",
      "[ 0.99999994 -1.          1.         -1.        ]\n",
      "[ 0.9999998 -1.         1.        -1.       ]\n",
      "[ 0.9999995 -1.         1.        -1.       ]\n",
      "[ 0.9999979 -1.         1.        -1.       ]\n",
      "[ 0.999986 -1.        1.       -1.      ]\n",
      "[ 0.9992409 -0.9999404  1.        -1.       ]\n",
      "[ 0.77485996 -0.94951     1.         -1.        ]\n",
      "[-0.9201162  0.7017424  1.        -1.       ]\n",
      "[-0.9952042   0.99301296  0.99999994 -1.        ]\n",
      "[-0.99885803  0.99105084  0.9998159  -1.        ]\n",
      "[-0.9985951   0.87535894  0.9285962  -1.        ]\n",
      "[-0.72426975  0.01186793 -0.5221459  -1.        ]\n",
      "[ 0.99925905 -0.9424079  -0.9907221  -1.        ]\n",
      "[ 1.         -0.9999991  -0.99999774 -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.9998331 -1.        -1.        -1.       ]\n",
      "[-0.96945906 -1.         -1.         -1.        ]\n",
      "[-0.99990356 -1.         -1.         -1.        ]\n",
      "[-0.99999446 -1.         -1.         -1.        ]\n",
      "[-0.9999999 -1.        -0.98811   -1.       ]\n",
      "[-1.         -1.          0.99997085 -1.        ]\n",
      "[-1.         -1.          0.64788663 -1.        ]\n",
      "[-0.9999999 -1.         0.9985507 -1.       ]\n",
      "[-0.99999833 -1.          0.9999132  -1.        ]\n",
      "[-0.99999344 -1.          0.9999997  -1.        ]\n",
      "[-0.9999882 -1.         1.        -1.       ]\n",
      "[-0.99998176 -1.          1.         -1.        ]\n",
      "[-0.9999602 -1.         1.        -1.       ]\n",
      "[-0.9999418 -1.         1.        -1.       ]\n",
      "[-0.99995273 -1.          1.         -1.        ]\n",
      "[-0.99998707 -1.          1.         -1.        ]\n",
      "[-0.9999986 -1.         1.        -1.       ]\n",
      "[-0.9999999  -1.          1.         -0.99999994]\n",
      "[-1.        -1.         1.        -0.9999997]\n",
      "[-1.        -1.         1.        -0.9999997]\n",
      "[-0.9999999 -1.         1.        -0.9999992]\n",
      "[-0.8654343  -1.          1.         -0.99999636]\n",
      "[ 0.99967784 -1.          0.99999994 -1.        ]\n",
      "[ 0.99999714 -1.          0.97762537 -1.        ]\n",
      "[ 0.9999884 -1.        -0.5328312 -1.       ]\n",
      "[ 0.9999997 -1.        -0.9999548 -1.       ]\n",
      "[ 1.         -1.         -0.99998975 -1.        ]\n",
      "[ 0.9999972  -1.         -0.99999595 -1.        ]\n",
      "[ 0.99993694 -1.         -0.23617464 -1.        ]\n",
      "[ 0.99371594 -1.          0.9999663  -1.        ]\n",
      "[ 0.9766352  -1.          0.99999887 -1.        ]\n",
      "[ 0.9965382 -0.9998499  0.9995705 -1.       ]\n",
      "[ 0.99948144 -0.9830537   0.9579135  -1.        ]\n",
      "[ 0.99982876 -0.7718649   0.6107548  -1.        ]\n",
      "[ 0.9994079  -0.10871582  0.834412   -1.        ]\n",
      "[ 0.9993754   0.68134487  0.8017203  -0.99999994]\n",
      "[ 0.9991441   0.9341686   0.8777674  -0.99999905]\n",
      "[ 0.99932367  0.9909017   0.83785576 -0.9999938 ]\n",
      "[ 0.9992454   0.9989512   0.7932234  -0.99997026]\n",
      "[ 0.99881774  0.999825    0.73398006 -0.99991435]\n",
      "[ 0.99742204  0.99992585  0.68560314 -0.999887  ]\n",
      "[ 0.9904613   0.99983376  0.7235799  -0.99996465]\n",
      "[ 0.9429115   0.9987912   0.8045111  -0.99999577]\n",
      "[ 0.5399202   0.983814    0.89097905 -0.9999996 ]\n",
      "[-0.88075626  0.37862146  0.9826626  -0.99999994]\n",
      "[-0.9991125 -0.987381   0.9997553 -1.       ]\n",
      "[-0.9999517  -0.9999106   0.99995565 -1.        ]\n",
      "[-0.9999961 -0.9999988  0.9979395 -1.       ]\n",
      "[-0.99998176 -0.99990463 -0.9972255  -0.999994  ]\n",
      "[ 0.7359623  0.9130044 -1.        -0.9999577]\n",
      "[ 0.99886143  0.9957064  -1.         -0.9999861 ]\n",
      "[ 0.99994427  0.99336666 -1.         -0.9999964 ]\n",
      "[ 0.99999297  0.96340823 -1.         -0.999999  ]\n",
      "[ 0.9999989  0.734774  -1.        -0.9999997]\n",
      "[ 0.99999976 -0.166564   -1.         -0.99999994]\n",
      "[ 0.9999998  -0.9038794  -1.         -0.99999994]\n",
      "[ 1.        -0.9786825 -1.        -1.       ]\n",
      "[ 1.         -0.99578273 -1.         -1.        ]\n",
      "[ 1.         -0.99947155 -1.         -1.        ]\n",
      "[ 1.        -0.9999226 -1.        -1.       ]\n",
      "[ 1.        -0.9999811 -1.        -1.       ]\n",
      "[ 1.         -0.99999344 -1.         -1.        ]\n",
      "[ 1.         -0.99999726 -1.         -1.        ]\n",
      "[ 1.         -0.99999845 -1.         -1.        ]\n",
      "[ 1.         -0.99999875 -1.         -1.        ]\n",
      "[ 1.        -0.9999988 -1.        -1.       ]\n",
      "[ 1.        -0.9999989 -1.        -1.       ]\n",
      "[ 1.         -0.99999934 -1.         -1.        ]\n",
      "[ 1.        -0.9999997 -1.        -1.       ]\n",
      "[ 1.         -0.99999994 -1.         -1.        ]\n",
      "[ 0.9999999 -1.        -1.        -1.       ]\n",
      "[ 0.99998343 -1.         -1.         -1.        ]\n",
      "[ 0.99369526 -1.         -1.         -1.        ]\n",
      "[ 0.01672259 -1.         -1.         -1.        ]\n",
      "[-0.49154997 -1.         -1.         -1.        ]\n",
      "[ 0.5008245 -1.        -1.        -1.       ]\n",
      "[-0.6581577 -1.        -1.        -1.       ]\n",
      "[ 0.5792116 -1.        -0.9999998 -1.       ]\n",
      "[ 0.06828701 -1.         -0.9999998  -1.        ]\n",
      "[-0.40802112 -1.         -0.9999957  -1.        ]\n",
      "[-0.90108824 -1.         -0.99915814 -1.        ]\n",
      "[-0.9924842 -1.        -0.9998348 -1.       ]\n",
      "[-0.99960685 -1.         -0.9999943  -1.        ]\n",
      "[-0.9999854  -1.         -0.99999964 -1.        ]\n",
      "[-0.99999934 -1.         -0.99999994 -1.        ]\n",
      "[-0.99999994 -1.         -1.         -1.        ]\n",
      "[-1.         -1.         -0.99999994 -1.        ]\n",
      "[-1.        -1.        -0.9995231 -1.       ]\n",
      "[-0.9999976 -1.        -0.7759005 -1.       ]\n",
      "[-0.9998646 -1.         0.8398778 -1.       ]\n",
      "[-0.9999891  -1.         -0.99887633 -1.        ]\n",
      "[-0.9999972 -1.        -0.9482649 -1.       ]\n",
      "[-0.9999992  -1.         -0.08115745 -1.        ]\n",
      "[-1.         -1.          0.28660986 -1.        ]\n",
      "[-1.        -1.         0.7616081 -1.       ]\n",
      "[-1.        -1.         0.8497732 -1.       ]\n",
      "[-1.         -1.          0.04222941 -1.        ]\n",
      "[-1.         -0.99999964 -0.9978821  -1.        ]\n",
      "[-1.         -0.99999994 -0.99999887 -1.        ]\n",
      "[-0.99999976 -0.9999939  -1.         -1.        ]\n",
      "[-0.9999995 -0.9998982 -1.        -1.       ]\n",
      "[-0.9999992 -0.9999927 -1.        -1.       ]\n",
      "[-0.60278916 -1.         -1.         -1.        ]\n",
      "[ 0.99999726 -1.         -1.         -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.93739355 -1.         -1.         -1.        ]\n",
      "[-0.9999563 -1.        -1.        -1.       ]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1. -1. -1. -1.]\n",
      "[-0.99999857 -1.         -1.         -1.        ]\n",
      "[-0.99994475 -1.         -1.         -1.        ]\n",
      "[-0.99991316 -1.         -1.         -1.        ]\n",
      "[-0.99999183 -1.         -1.         -1.        ]\n",
      "[-0.9999998 -1.        -0.9999161 -1.       ]\n",
      "[-0.99999905 -1.         -0.9027928  -1.        ]\n",
      "[-0.9999989  -0.99999994 -0.9951632  -1.        ]\n",
      "[-0.9999987 -0.9999943 -1.        -1.       ]\n",
      "[-1.        -0.9999674 -1.        -1.       ]\n",
      "[-1.         -0.99995536 -1.         -1.        ]\n",
      "[-1.         -0.99999976 -1.         -1.        ]\n",
      "[-0.9999999 -1.        -1.        -1.       ]\n",
      "[ 0.9999998 -1.        -1.        -1.       ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1.        -1.        -0.9999966 -1.       ]\n",
      "[ 1.         -1.         -0.99837554 -1.        ]\n",
      "[ 1.         -1.         -0.99999994 -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.99999124 -1.         -1.         -1.        ]\n",
      "[-0.9986221 -1.        -1.        -1.       ]\n",
      "[-1. -1. -1. -1.]\n",
      "[-0.9999995 -1.        -1.        -1.       ]\n",
      "[-0.9997767  -1.         -0.99999994 -1.        ]\n",
      "[-0.9989024 -1.        -0.9998301 -1.       ]\n",
      "[-0.99692214 -1.          0.07514385 -1.        ]\n",
      "[-0.99994034 -1.          0.99999535 -1.        ]\n",
      "[-0.9999615 -1.         0.9999747 -1.       ]\n",
      "[-0.99999946 -1.          0.98713356 -1.        ]\n",
      "[-1.        -0.999999  -0.9999492 -1.       ]\n",
      "[-0.99999976 -0.99999005 -1.         -1.        ]\n",
      "[-0.9999994  -0.99999464 -1.         -1.        ]\n",
      "[-1. -1. -1. -1.]\n",
      "[-1. -1. -1. -1.]\n",
      "[-0.9729804 -1.        -1.        -1.       ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1.        -1.        -0.9999801 -1.       ]\n",
      "[ 1.         -1.         -0.53399277 -1.        ]\n",
      "[ 1.         -1.         -0.99936575 -1.        ]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 1. -1. -1. -1.]\n",
      "[ 0.9970172 -1.        -1.        -1.       ]\n",
      "[-0.99998343 -1.         -1.         -1.        ]\n",
      "[-0.99999434 -1.         -1.         -1.        ]\n",
      "[ 0.51486546 -1.         -1.         -1.        ]\n",
      "[ 0.99999946 -1.         -0.9998431  -1.        ]\n",
      "[ 1.        -1.         0.3714492 -1.       ]\n",
      "[ 1.        -1.         0.9999996 -1.       ]\n",
      "[ 0.99999994 -1.          0.999998   -1.        ]\n",
      "[ 0.9999885  -1.          0.99999976 -1.        ]\n",
      "[ 0.97562057 -1.          0.99999857 -1.        ]\n",
      "[-0.98063827 -0.99999624  0.9982744  -1.        ]\n",
      "[-0.9999998  -0.99839187 -0.8466766  -1.        ]\n",
      "[ 0.6020959  -0.9996      0.98634034 -1.        ]\n",
      "[-1.          0.987245   -0.99999183 -1.        ]\n",
      "[ 0.8855495  0.9094365 -0.5864438 -1.       ]\n",
      "[ 0.27153322  0.97880006  0.12784241 -1.        ]\n",
      "[-0.99982953  0.99977475 -0.9983092  -1.        ]\n",
      "[-0.99953866  0.9998239  -0.99999833 -1.        ]\n",
      "[-0.7363685   0.985743   -0.99999994 -1.        ]\n",
      "[ 0.99571663 -0.52568364 -1.         -1.        ]\n",
      "0.5399999879300594\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations[0]\n",
    "while True:\n",
    "    actions = agent.act(states, add_noise=False)\n",
    "    print(actions)\n",
    "    #env.render()\n",
    "    env_info = env.step(actions)[brain_name] \n",
    "    next_states = env_info.vector_observations[0]\n",
    "    rewards = env_info.rewards\n",
    "   # print(rewards)\n",
    "    scores += rewards[0]                         \n",
    "    dones = env_info.local_done\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break \n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}